{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YDSHPERE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YDSHPERE:\n",
    "    %pip install efficientnet_pytorch\n",
    "else:\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from efficientnet_pytorch import model as enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "if not KAGGLE: os.environ['CUDA_VISIBLE_DEVICES'] = '1' \n",
    "else: pass\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "VER = 'v2'\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/seti-breakthrough-listen'\n",
    "    MDLS_PATH = f'../input/seti-models-{VER}'\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATH = f'./models_{VER}'\n",
    "TH = None\n",
    "TTAS = [0]\n",
    "FOLDS = [0, 1, 2, 3]\n",
    "IMGS_PATH = f'{DATA_PATH}/test'\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    df_subm = pd.read_csv(f'{DATA_PATH}/sample_submission.csv').sample(100).reset_index(drop=True)\n",
    "else:\n",
    "    df_subm = pd.read_csv(f'{DATA_PATH}/sample_submission.csv')\n",
    "print (df_subm.shape)\n",
    "df_subm['img_path'] = df_subm['id'].apply(lambda x: f'{IMGS_PATH}/{x[0]}/{x}.npy')\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_PATH}/params.json') as file:\n",
    "    params = json.load(file)\n",
    "WORKERS = 2 if KAGGLE else 8 #params['workers']\n",
    "print('loaded params:', params, '\\n')\n",
    "\n",
    "if not TH:\n",
    "    with open(f'{MDLS_PATH}/th.json') as file:\n",
    "        th = json.load(file)\n",
    "    print('threshold:', th)\n",
    "else: \n",
    "    print('threshold:', TH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img, axis=0):\n",
    "    if axis == 1:\n",
    "        return img[:, ::-1, :]\n",
    "    elif axis == 2:\n",
    "        return img[:, :, ::-1]\n",
    "    elif axis == 3:\n",
    "        return img[:, ::-1, ::-1]\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "class ClassificationDataset:\n",
    "    \n",
    "    def __init__(self, img_paths, targets, tta): \n",
    "        self.img_paths = img_paths\n",
    "        self.targets = targets\n",
    "        self.tta = tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, item):      \n",
    "        img = np.load(self.img_paths[item]).astype(np.float32)\n",
    "        img = flip(img, axis=self.tta)\n",
    "        targets = self.targets[item]        \n",
    "        return {\n",
    "            'image': torch.tensor(img.copy(), dtype=torch.float),\n",
    "            'targets': torch.tensor(targets, dtype=torch.float),\n",
    "        }\n",
    "\n",
    "class EffNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, out_dim):\n",
    "        super(EffNet, self).__init__()\n",
    "        self.enet = enet.EfficientNet.from_name(params['backbone'])\n",
    "        nc = self.enet._fc.in_features\n",
    "        self.enet._fc = nn.Identity()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=6, \n",
    "            out_channels=3, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=3, \n",
    "            bias=False\n",
    "        )\n",
    "        self.myfc = nn.Sequential(\n",
    "            nn.Dropout(params['dropout']),\n",
    "            nn.Linear(nc, int(nc / 4)),\n",
    "            nn.Dropout(params['dropout']),\n",
    "            nn.Linear(int(nc / 4), out_dim)\n",
    "        )\n",
    "    \n",
    "    def extract(self, x):\n",
    "        return self.enet(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.extract(x)\n",
    "        x = self.myfc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for n_fold in FOLDS:\n",
    "    model = EffNet(params=params, out_dim=1) \n",
    "    path = '{}/model_best_{}.pth'.format(MDLS_PATH, n_fold)\n",
    "    state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    model.cuda(DEVICE)\n",
    "    models.append(model)\n",
    "    print('loaded:', path)\n",
    "del state_dict, model\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, loaders = [], []\n",
    "for tta in TTAS:\n",
    "    subm_imgs = df_subm.loc[:, 'img_path'].values\n",
    "    subm_targets = df_subm.loc[:, 'target'].values\n",
    "    dataset = ClassificationDataset(\n",
    "        img_paths=subm_imgs, \n",
    "        targets=subm_targets,\n",
    "        tta=tta\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=False, \n",
    "        num_workers=WORKERS\n",
    "    )\n",
    "    datasets.append(dataset)\n",
    "    loaders.append(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "with torch.no_grad():\n",
    "    for i, model in enumerate(models):\n",
    "        for j, loader in enumerate(loaders):\n",
    "            logits_tta = []\n",
    "            for data in tqdm(loader, desc=f'model {i}, loader {j}'):\n",
    "                img_data = data['image']\n",
    "                img_data = img_data.to(DEVICE)\n",
    "                preds = np.squeeze(model(img_data).sigmoid().cpu().numpy())\n",
    "                logits_tta.extend(preds.tolist())\n",
    "            logits.append(logits_tta)\n",
    "logits = np.mean(logits, axis=0)\n",
    "logits = np.squeeze(np.vstack(logits))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.loc[:, 'target'] = logits\n",
    "df_subm.drop(['img_path'], axis=1, inplace=True)\n",
    "print(df_subm.shape)\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
