{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YDSHPERE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "s606juodg2gxygmlhahd2",
    "execution_id": "95d26adc-7477-443f-9a9a-bfee7c22406c"
   },
   "outputs": [],
   "source": [
    "if YDSHPERE:\n",
    "    %pip install efficientnet_pytorch\n",
    "else:\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "urbjiiokl430h0wt13n8j",
    "execution_id": "c718a26b-da1e-4629-95c2-994613c8bbf2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "from efficientnet_pytorch import model as enet\n",
    "import albumentations as A\n",
    "#warnings.filterwarnings('ignore', category=UserWarning) \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "77k9rr39flsmzx7vfecyv",
    "execution_id": "b7686796-9f7f-4404-a97b-575a6a7e2e15"
   },
   "outputs": [],
   "source": [
    "VER = 'v6'\n",
    "DEBUG = False\n",
    "PARAMS = {\n",
    "    'version': VER,\n",
    "    'img_size': 380,\n",
    "    'mixup': True,\n",
    "    'folds': 4,\n",
    "    'folds_train': None,\n",
    "    'batch_size': 16,\n",
    "    'workers': 16,\n",
    "    'epochs': 4 if DEBUG else 40,\n",
    "    'patience': 4,\n",
    "    'warmup': False,\n",
    "    'backbone': 'efficientnet-b1', # 'efficientnet-bX' or 'resnext'\n",
    "    'dropout': .4,\n",
    "    'seed': 2020,\n",
    "    'lr': .0005,\n",
    "    'comments': ''\n",
    "}\n",
    "DATA_PATH = './data'\n",
    "IMGS_PATH = f'{DATA_PATH}/train'\n",
    "MDLS_PATH = f'./models_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/params.json', 'w') as file:\n",
    "    json.dump(PARAMS, file)\n",
    "\n",
    "def seed_all(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return random_state    \n",
    "\n",
    "random_state = seed_all(PARAMS['seed'])\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mu0slqvliwepmehoktunem",
    "execution_id": "ea6f0a05-7cca-4fcd-bf40-7ec9d7497717"
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    df = pd.read_csv(f'{DATA_PATH}/train_labels.csv').sample(100).reset_index(drop=True)\n",
    "else:\n",
    "    df = pd.read_csv(f'{DATA_PATH}/train_labels.csv')\n",
    "print (df.shape)\n",
    "df['img_path'] = df['id'].apply(lambda x: f'{IMGS_PATH}/{x[0]}/{x}.npy')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = A.Compose([\n",
    "    A.Resize(PARAMS['img_size'], \n",
    "             PARAMS['img_size'], \n",
    "             cv2.INTER_NEAREST),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.Transpose(p=.25),\n",
    "    A.ShiftScaleRotate(p=.25, rotate_limit=0)\n",
    "])\n",
    "val_aug = A.Compose([\n",
    "    A.Resize(PARAMS['img_size'], \n",
    "             PARAMS['img_size'], \n",
    "             cv2.INTER_NEAREST),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dr6m6fxy9ow1h7o7tcjpxe",
    "execution_id": "f4090b24-e02c-493b-9932-8e72465c83b6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class ClassificationDataset:\n",
    "    \n",
    "    def __init__(self, img_paths, targets, aug, tta=None): \n",
    "        self.img_paths = img_paths\n",
    "        self.targets = targets\n",
    "        self.aug = aug\n",
    "        self.tta = tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, item):      \n",
    "        img = np.load(self.img_paths[item]).astype(np.float)\n",
    "        targets = self.targets[item]\n",
    "        img = np.vstack(img).astype(np.float)\n",
    "        img = self.aug(image=img)['image'][np.newaxis, ]\n",
    "        if self.tta: \n",
    "            img = flip(img, axis=self.tta)\n",
    "        return {\n",
    "            'image': torch.tensor(img.copy(), dtype=torch.float),\n",
    "            'targets': torch.tensor(targets, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "o2eliox8egrdw7lr7d03z9",
    "execution_id": "51a62148-356f-4282-abb3-5f6caeea1c94"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class EffNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, out_dim, infer=False):\n",
    "        super(EffNet, self).__init__()\n",
    "        if infer:\n",
    "            self.enet = enet.EfficientNet.from_name(params['backbone'])\n",
    "        else:\n",
    "            self.enet = enet.EfficientNet.from_pretrained(params['backbone'])\n",
    "        nc = self.enet._fc.in_features\n",
    "        self.enet._fc = nn.Identity()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1 if params['mixup'] else 6, \n",
    "            out_channels=3, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=3, \n",
    "            bias=False\n",
    "        )\n",
    "        if params['dropout']:\n",
    "            self.myfc = nn.Sequential(\n",
    "                nn.Dropout(params['dropout']),\n",
    "                nn.Linear(nc, int(nc / 4)),\n",
    "                nn.Dropout(params['dropout']),\n",
    "                nn.Linear(int(nc / 4), out_dim)\n",
    "            )\n",
    "        else:\n",
    "            self.myfc = nn.Linear(nc, out_dim)\n",
    "        \n",
    "    \n",
    "    def extract(self, x):\n",
    "        return self.enet(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.extract(x)\n",
    "        x = self.myfc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "a4n1oha9tdqclgthgfcohc",
    "execution_id": "2661b9f3-dd96-429f-9e9f-125d0299949f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train(data_loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    for data in tqdm(data_loader, position=0, leave=True, desc='training'):\n",
    "        inputs = data['image']\n",
    "        targets = data['targets']\n",
    "        if PARAMS['mixup']:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(\n",
    "                inputs, \n",
    "                targets.view(-1, 1), \n",
    "                use_cuda=True\n",
    "            )\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets_a = targets_a.to(device, dtype=torch.float)\n",
    "            targets_b = targets_b.to(device, dtype=torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(\n",
    "                nn.BCEWithLogitsLoss(), \n",
    "                outputs, targets_a, targets_b, lam\n",
    "            )\n",
    "        else:\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def evaluate(data_loader, model, device):\n",
    "    model.eval()\n",
    "    val_targets = []\n",
    "    val_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, position=0, leave=True, desc='evaluating'):\n",
    "            inputs = data['image']\n",
    "            targets = data['targets']\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            output = model(inputs).sigmoid()\n",
    "            targets = targets.detach().cpu().numpy().tolist()\n",
    "            output = output.detach().cpu().numpy().tolist()\n",
    "            val_targets.extend(targets)\n",
    "            val_outputs.extend(output)\n",
    "    return val_outputs, val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "zrelbtb9zg95gcxdjr8yg",
    "execution_id": "ee008ff3-96bf-4a7e-8537-8bd5e1ebc205"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(PARAMS['folds'], shuffle=True, random_state=PARAMS['seed'])\n",
    "df['fold'] = -1\n",
    "for i, (train_idxs, val_idxs) in enumerate(skf.split(df, df['target'])):\n",
    "    df.loc[val_idxs, 'fold'] = i\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x7baqzspxynoa7oewztfcm",
    "execution_id": "cc2aed24-e01f-4b13-b059-c7efe378ad1e"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "preds_val = []\n",
    "\n",
    "if DEBUG:\n",
    "    n_folds_train = 2\n",
    "else:\n",
    "    n_folds_train = PARAMS['folds'] if not PARAMS['folds_train'] else PARAMS['folds_train']\n",
    "start_folds_train = 0\n",
    "\n",
    "for fold_num in range(start_folds_train, n_folds_train):\n",
    "    print('=' * 20, 'FOLD:', fold_num, '=' * 20)\n",
    "    train_idxs = np.where((df['fold'] != fold_num))[0]\n",
    "    val_idxs = np.where((df['fold'] == fold_num))[0]\n",
    "    train_imgs, val_imgs = df.loc[train_idxs, 'img_path'].values, df.loc[val_idxs, 'img_path'].values\n",
    "    train_targets, val_targets = df.loc[train_idxs, 'target'].values, df.loc[val_idxs, 'target'].values\n",
    "    train_dataset = ClassificationDataset(\n",
    "        img_paths=train_imgs, \n",
    "        targets=train_targets,\n",
    "        aug=train_aug\n",
    "    )\n",
    "    val_dataset = ClassificationDataset(\n",
    "        img_paths=val_imgs, \n",
    "        targets=val_targets,\n",
    "        aug=val_aug\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        shuffle=True, \n",
    "        num_workers=PARAMS['workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        shuffle=False, \n",
    "        num_workers=PARAMS['workers']\n",
    "    )\n",
    "    model = EffNet(params=PARAMS, out_dim=1)\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=PARAMS['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, PARAMS['epochs'])\n",
    "    print('train len:', len(train_dataset),'| val len:', len(val_dataset))\n",
    "    best_file = '{}/model_best_{}.pth'.format(MDLS_PATH, fold_num)\n",
    "    roc_auc_max = 0\n",
    "    epochs_no_improve = 0\n",
    "    for epoch in tqdm(range(PARAMS['epochs']), desc='epochs'):\n",
    "        print(time.ctime(), 'epoch:', epoch)\n",
    "        train(train_loader, model, optimizer, device=DEVICE)\n",
    "        preds, val_targets = evaluate(val_loader, model, device=DEVICE)\n",
    "        roc_auc = metrics.roc_auc_score(val_targets, preds)\n",
    "        scheduler.step()\n",
    "        content = '{} epoch {}, lr: {:.8f}, ROC-AUC: {:.4f}'.format(\n",
    "            time.ctime(),\n",
    "            epoch, \n",
    "            optimizer.param_groups[0]['lr'], \n",
    "            roc_auc\n",
    "        )\n",
    "        print(content)\n",
    "        with open('{}/log_{}.txt'.format(MDLS_PATH, fold_num), 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "        if roc_auc > roc_auc_max:\n",
    "            torch.save(model.state_dict(), best_file)\n",
    "            print('ROC-AUC improved {:.4f} --> {:.4f} model saved'.format(roc_auc_max, roc_auc))\n",
    "            roc_auc_max = roc_auc\n",
    "            preds_best = np.squeeze(preds)\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PARAMS['patience']:\n",
    "            print('no improve for', epochs_no_improve, 'epochs | early stopping')\n",
    "            early_stop = True\n",
    "            break\n",
    "    preds_val.extend(preds_best)\n",
    "    torch.save(\n",
    "        model.state_dict(), \n",
    "        os.path.join('{}/model_final_{}.pth'.format(MDLS_PATH, fold_num))\n",
    "    )\n",
    "    del model, train_dataset, val_dataset, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mjax9kor5ykt30mayd21n",
    "execution_id": "02e73e8f-99ad-433f-889f-73b5f4139630"
   },
   "outputs": [],
   "source": [
    "roc_auc_max, th_max = 0, 0\n",
    "target_val = df.target.values\n",
    "for th in np.linspace(.1, 1, 100):\n",
    "    try:\n",
    "        roc_auc = metrics.roc_auc_score(np.array(preds_val) > th, target_val)\n",
    "        if roc_auc > roc_auc_max:\n",
    "            roc_auc_max = roc_auc\n",
    "            th_max = th\n",
    "    except:\n",
    "        pass\n",
    "print('ROC-AUC max:', np.round(roc_auc_max, 2), '| th max:', np.round(th_max, 2))\n",
    "with open(f'{MDLS_PATH}/th.json', 'w') as file:\n",
    "    json.dump({\n",
    "        'ROC-AUC max': roc_auc_max, \n",
    "        'th max': th_max,\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dv1d45j1j5mdienwqzu6x6",
    "execution_id": "4d7e0d40-0cd6-41c7-a2be-4c1b927417cb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notebookId": "994869e9-f4c6-4235-a36c-1880ecd52a1b"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
